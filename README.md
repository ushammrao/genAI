https://build.nvidia.com/
## Gen AI applications using RAG
App1: RAG pipeline using Nvidia-Embeddings. Inference Llama3 on Nvidia NIM. 

App2: Amazon Titan for embedding. Inference models (Claude & Llma2) on Bedrock 

## Enterprise GenAI apps I built in 2025:

GenAI app built w/ Bedrock for Enterprise-P2C: https://excalidraw.com/#json=Otvz3TfI_191OiiZf51pR,fzWswIP69p0BvRxTnkB2hw 

Kai-AI powered IT-Sec Ops: https://excalidraw.com/#json=ev9tYSm2uquSVcJVoNlUP,jdMRi3zrqM7uH4Z2z_IRdg

Documents -> Split into Chunks -> Create Embedings -> Vector Store

streamlit run app.py

<img width="950" height="596" alt="NVDA-NIMGenAIRAG_UR25" src="https://github.com/user-attachments/assets/d81d5333-f827-4e71-bb95-f9bb6805d650" />

<img width="1400" height="1265" alt="image" src="https://github.com/user-attachments/assets/735636e7-ee9b-4705-a9ca-cf36b8217bcc" />
